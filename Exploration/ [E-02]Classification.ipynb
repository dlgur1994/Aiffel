{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "czech-giving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(random_state=17): 0.8266508772376999\n",
      "RandomForestClassifier(random_state=17): 0.9622816477550563\n",
      "SVC(random_state=17): 0.9840710163841433\n",
      "SGDClassifier(random_state=17): 0.9378717635704982\n",
      "LogisticRegression(max_iter=5000, random_state=17): 0.9649599002074807\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# 데이터 준비\n",
    "digits = load_digits()\n",
    "\n",
    "# Feature Data 지정하기\n",
    "digits_feature = digits.data\n",
    "\n",
    "# Label Data 지정하기\n",
    "digits_label = digits.target\n",
    "\n",
    "# Target Names 출력해 보기\n",
    "# print(digits_label)\n",
    "\n",
    "# 데이터 Describe 해 보기\n",
    "# print(digits.DESCR)\n",
    "\n",
    "# train, test 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_feature, digits_label, test_size=0.2, random_state=17)\n",
    "\n",
    "# models\n",
    "dt = DecisionTreeClassifier(random_state=17)\n",
    "rf = RandomForestClassifier(random_state=17)\n",
    "svm = svm.SVC(random_state=17)\n",
    "sgd = SGDClassifier(random_state=17)\n",
    "lr = LogisticRegression(random_state=17, max_iter=5000)\n",
    "models = [dt, rf, svm, sgd, lr]\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(str(model) + ': ' + str(f1_score(y_test, y_pred, average='macro')))\n",
    "    # print(classification_report(y_test, y_pred))\n",
    "    # print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "'''\n",
    "손글씨 분류 경우에는 오류가 발생하여도 생명 혹은 막대한 피해를 끼치지 않기 때문에 전반적인 성능이 높은 것이 좋다.\n",
    "따라서 precision과 recall이 같이 높은 모델, 즉 F1 Score가 높은 것을 선택하면 된다. \n",
    "위의 코드를 기준으로는 모델이 SVC인 경우의 F1 score가 가장 높으므로 이 경우에는 SVC를 사용해야 한다.\n",
    "그리고 위의 데이터 셋의 경우 각 카테고리별 데이터의 비율이 비슷하므로 Recall 수치 중 macro avg을 사용해도 무방하다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-gazette",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "sealed-branch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(random_state=17): 0.9754062362758015\n",
      "RandomForestClassifier(random_state=17): 1.0\n",
      "SVC(random_state=17): 0.5617875056999544\n",
      "SGDClassifier(random_state=17): 0.7317043740573151\n",
      "LogisticRegression(max_iter=5000, random_state=17): 0.9754062362758015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# 데이터 준비\n",
    "wines = load_wine()\n",
    "\n",
    "# Feature Data 지정하기\n",
    "wines_feature = wines.data\n",
    "\n",
    "# Label Data 지정하기\n",
    "wines_label = wines.target\n",
    "\n",
    "# Target Names 출력해 보기\n",
    "# print(wines_label)\n",
    "\n",
    "# 데이터 Describe 해 보기\n",
    "# print(wines.DESCR)\n",
    "\n",
    "# train, test 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(wines_feature, wines_label, test_size=0.2, random_state=17)\n",
    "\n",
    "# models\n",
    "dt = DecisionTreeClassifier(random_state=17)\n",
    "rf = RandomForestClassifier(random_state=17)\n",
    "svm = svm.SVC(random_state=17)\n",
    "sgd = SGDClassifier(random_state=17)\n",
    "lr = LogisticRegression(random_state=17, max_iter=5000)\n",
    "models = [dt, rf, svm, sgd, lr]\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(str(model) + ': ' + str(f1_score(y_test, y_pred, average='macro')))\n",
    "    # print(classification_report(y_test, y_pred))\n",
    "    # print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-magnitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "'''\n",
    "와인 분류 경우에도 오류가 발생으로 인해 생명 혹은 막대한 피해를 끼치지 않기 때문에 전반적인 성능이 높은 것이 좋다.\n",
    "따라서 precision과 recall이 같이 높은 모델, 즉 F1 Score가 높은 것을 선택하면 된다. \n",
    "위의 코드를 기준으로는 모델이 Random Forest인 경우의 F1 score가 가장 높으므로 이 경우에는 Random Forest를 사용해야 한다.\n",
    "그리고 위의 데이터 셋의 경우에도 각 카테고리별 데이터의 비율이 거의 비슷하므로 Recall 수치 중 macro avg을 사용해도 무방하다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-balance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "major-wrist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(random_state=17): 0.9078947368421053\n",
      "RandomForestClassifier(random_state=17): 0.9605263157894737\n",
      "SVC(random_state=17): 0.9144736842105263\n",
      "SGDClassifier(random_state=17): 0.9013157894736842\n",
      "LogisticRegression(max_iter=1000, random_state=17): 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 데이터 준비\n",
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "# Feature Data 지정하기\n",
    "breast_cancer_feature = breast_cancer.data\n",
    "\n",
    "# Label Data 지정하기\n",
    "breast_cancer_label = breast_cancer.target\n",
    "\n",
    "# Target Names 출력해 보기\n",
    "# print(breast_cancer_label)\n",
    "\n",
    "# 데이터 Describe 해 보기\n",
    "# print(breast_cancer.DESCR)\n",
    "\n",
    "# train, test 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(breast_cancer_feature, breast_cancer_label, test_size=0.2, random_state=17)\n",
    "\n",
    "# models\n",
    "dt = DecisionTreeClassifier(random_state=17)\n",
    "rf = RandomForestClassifier(random_state=17)\n",
    "svm = svm.SVC(random_state=17)\n",
    "sgd = SGDClassifier(random_state=17)\n",
    "lr = LogisticRegression(random_state=17, max_iter=1000)\n",
    "models = [dt, rf, svm, sgd, lr]\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(str(model) + ': ' + str(recall_score(y_test, y_pred, average='macro')))\n",
    "    # print(classification_report(y_test, y_pred))\n",
    "    # print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-housing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 평가\n",
    "'''\n",
    "유방암 예측 경우에는 양성인 사람들을 많이 예측할수록 좋다. \n",
    "따라서 음성으로 예측된 것 중 실제 양성인 것, 즉 FN이 가장 작고 TP가 가장 높아야 하므로 \n",
    "이 경우에는 Recall이 중요한 평가 기준으로 사용되어야 한다.\n",
    "위의 코드를 기준으로는 Random Forest인 경우의 Recall이 가장 높으므로 이 경우에는 Random Forest를 사용해야 한다.\n",
    "그리고 위의 데이터 셋의 경우도 양성과 음성의 비율이 거의 비슷하므로 Recall 수치 중 macro avg을 사용해도 무방하다.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-alert",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-investigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "회고\n",
    "- 이번 프로젝트에서 어려웠던 점\n",
    "    - confusion matrix를 볼 때마다 항상 정의 내용들이 헷갈려서 계속 왔다갔다 했던 점이 어려웠다.\n",
    "- 프로젝트를 진행하면서 알아낸 점 혹은 아직 모호한 점\n",
    "    - 평가 성능 지표를 정할 때 생명 혹은 사회적인 이슈가 있는 특수한 케이스가 아닌 경우에는 전반적인 성능 지표인 F1 Score를 사용하면 된다.  \n",
    "- 루브릭 평가 지표를 맞추기 위해 시도한 것들\n",
    "    - 1. 코드를 계속 돌려도 일정한 결과값이 나오도록 각 모델마다 random state 를 설정했다.\n",
    "    - 2. 각 성능 평가 지표의 특성들에 대해 찾아보며 경우에 따라 적절한 평가 지표를 적용했다.\n",
    "- 만약에 루브릭 평가 관련 지표를 달성 하지 못했을 때, 이유에 관한 추정 (없음)\n",
    "- 자기 다짐\n",
    "    - confusion matrix를 볼 때마다 외우려고 했지만 그동안은 꼼꼼하게 보지 않았던 것 같다. 그래서 앞으로는 새로운 내용을 배울 때 조금 더 꼼꼼하게 익혀야겠다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
